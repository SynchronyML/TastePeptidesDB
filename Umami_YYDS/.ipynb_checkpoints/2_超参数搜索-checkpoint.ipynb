{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5391be65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.utils import shuffle \n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve, auc,roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score,train_test_split,cross_validate, StratifiedKFold\n",
    "from sklearn.utils  import shuffle \n",
    "import joblib\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.utils import shuffle \n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve, auc,roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a92daac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_smote = pd.read_csv(\"SMOTE增强数据.csv\")\n",
    "# df_smote = shuffle(df_smote) # 这一步没有用，因为最后标准化还是会将数值的顺序进行调整\n",
    "X = df_smote.iloc[:,:-1]\n",
    "Y = df_smote[\"taste_num\"]\n",
    "columns = X.columns\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe65ac7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "GtBossT = GradientBoostingClassifier(\n",
    "    random_state=0,\n",
    "    criterion='friedman_mse',\n",
    "    loss='deviance',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28240bb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e972a26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class sklearn.ensemble.GradientBoostingClassifier(*, loss='deviance', learning_rate=0.1, n_estimators=100, subsample=1.0, \n",
    "#                                                   criterion='friedman_mse', min_samples_split=2, min_samples_leaf=1, \n",
    "#                                                   min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0, \n",
    "#                                                   init=None, random_state=None, max_features=None, verbose=0, \n",
    "#                                                   max_leaf_nodes=None, warm_start=False, \n",
    "#                                                   validation_fraction=0.1, n_iter_no_change=None, tol=0.0001, ccp_alpha=0.0)[source]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89e0e981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200, 210, 220, 230, 240, 250, 260, 270, 280, 290, 300, 311, 321, 331, 341, 351, 361, 371, 381, 391, 401, 411, 421, 431, 441, 451, 461, 471, 481, 491, 501, 511, 521, 531, 541, 551, 561, 571, 581, 591, 601, 612, 622, 632, 642, 652, 662, 672, 682, 692, 702, 712, 722, 732, 742, 752, 762, 772, 782, 792, 802, 812, 822, 832, 842, 852, 862, 872, 882, 892, 902, 913, 923, 933, 943, 953, 963, 973, 983, 993, 1003, 1013, 1023, 1033, 1043, 1053, 1063, 1073, 1083, 1093, 1103, 1113, 1123, 1133, 1143, 1153, 1163, 1173, 1183, 1193, 1203, 1214, 1224, 1234, 1244, 1254, 1264, 1274, 1284, 1294, 1304, 1314, 1324, 1334, 1344, 1354, 1364, 1374, 1384, 1394, 1404, 1414, 1424, 1434, 1444, 1454, 1464, 1474, 1484, 1494, 1504, 1515, 1525, 1535, 1545, 1555, 1565, 1575, 1585, 1595, 1605, 1615, 1625, 1635, 1645, 1655, 1665, 1675, 1685, 1695, 1705, 1715, 1725, 1735, 1745, 1755, 1765, 1775, 1785, 1795, 1805, 1816, 1826, 1836, 1846, 1856, 1866, 1876, 1886, 1896, 1906, 1916, 1926, 1936, 1946, 1956, 1966, 1976, 1986, 1996, 2006, 2016, 2026, 2036, 2046, 2056, 2066, 2076, 2086, 2096, 2106, 2117, 2127, 2137, 2147, 2157, 2167, 2177, 2187, 2197, 2207, 2217, 2227, 2237, 2247, 2257, 2267, 2277, 2287, 2297, 2307, 2317, 2327, 2337, 2347, 2357, 2367, 2377, 2387, 2397, 2407, 2418, 2428, 2438, 2448, 2458, 2468, 2478, 2488, 2498, 2508, 2518, 2528, 2538, 2548, 2558, 2568, 2578, 2588, 2598, 2608, 2618, 2628, 2638, 2648, 2658, 2668, 2678, 2688, 2698, 2708, 2719, 2729, 2739, 2749, 2759, 2769, 2779, 2789, 2799, 2809, 2819, 2829, 2839, 2849, 2859, 2869, 2879, 2889, 2899, 2909, 2919, 2929, 2939, 2949, 2959, 2969, 2979, 2989, 2999, 3010], 'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51], 'min_samples_split': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}\n",
      "Fitting 5 folds for each of 150000 candidates, totalling 750000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:922: UserWarning: One or more of the test scores are non-finite: [nan nan nan ...  1.  1.  1.]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{81385.20731568336}\n",
      "{'max_depth': 1, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "begin_time = time()\n",
    "# Search optimal hyperparameter\n",
    "n_estimators_range=[int(x) for x in np.linspace(start=10,stop=3010,num=300)]\n",
    "max_depth_range=[int(x) for x in np.linspace(1,51,num=50)]\n",
    "min_samples_split_range=[1,2,3,4,5,6,7,8,9,10]\n",
    "max_features=['sqrt','log2']\n",
    "# min_samples_leaf=\n",
    "\n",
    "\n",
    "random_forest_hp_range={'n_estimators':n_estimators_range,\n",
    "                        'max_depth':max_depth_range,\n",
    "                        'min_samples_split':min_samples_split_range,\n",
    "                        }\n",
    "print(random_forest_hp_range)\n",
    "\n",
    "estimator_all_roc = GridSearchCV(estimator=GtBossT,\n",
    "                                 param_grid=random_forest_hp_range,\n",
    "                                 cv=cv,\n",
    "                                 n_jobs=-1,\n",
    "                                 scoring=\"accuracy\",verbose=2)\n",
    "# %%time\n",
    "estimator_all_roc.fit(X, Y)\n",
    "end_time = time()\n",
    "print({end_time - begin_time})\n",
    "print(estimator_all_roc.best_params_)\n",
    "print(estimator_all_roc.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15278823",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame(estimator_all_roc.cv_results_)\n",
    "df_fig = tmp[[\"mean_test_score\",\"params\"]]\n",
    "df_fig.to_csv(\"tmp.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04063e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150000, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7984ce20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\AppData\\Local\\Temp/ipykernel_24280/155708207.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_fig[\"n_estimators\"] = 1\n",
      "C:\\Users\\Alex\\AppData\\Local\\Temp/ipykernel_24280/155708207.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_fig['max_depth'] = 1\n",
      "C:\\Users\\Alex\\AppData\\Local\\Temp/ipykernel_24280/155708207.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_fig[\"min_samples_split\"] = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>params</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 1, 'n_es...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 1, 'n_es...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 1, 'n_es...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 1, 'n_es...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 1, 'n_es...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149995</th>\n",
       "      <td>1.0</td>\n",
       "      <td>{'max_depth': 51, 'min_samples_split': 10, 'n_...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149996</th>\n",
       "      <td>1.0</td>\n",
       "      <td>{'max_depth': 51, 'min_samples_split': 10, 'n_...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149997</th>\n",
       "      <td>1.0</td>\n",
       "      <td>{'max_depth': 51, 'min_samples_split': 10, 'n_...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149998</th>\n",
       "      <td>1.0</td>\n",
       "      <td>{'max_depth': 51, 'min_samples_split': 10, 'n_...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149999</th>\n",
       "      <td>1.0</td>\n",
       "      <td>{'max_depth': 51, 'min_samples_split': 10, 'n_...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        mean_test_score                                             params  \\\n",
       "0                   NaN  {'max_depth': 1, 'min_samples_split': 1, 'n_es...   \n",
       "1                   NaN  {'max_depth': 1, 'min_samples_split': 1, 'n_es...   \n",
       "2                   NaN  {'max_depth': 1, 'min_samples_split': 1, 'n_es...   \n",
       "3                   NaN  {'max_depth': 1, 'min_samples_split': 1, 'n_es...   \n",
       "4                   NaN  {'max_depth': 1, 'min_samples_split': 1, 'n_es...   \n",
       "...                 ...                                                ...   \n",
       "149995              1.0  {'max_depth': 51, 'min_samples_split': 10, 'n_...   \n",
       "149996              1.0  {'max_depth': 51, 'min_samples_split': 10, 'n_...   \n",
       "149997              1.0  {'max_depth': 51, 'min_samples_split': 10, 'n_...   \n",
       "149998              1.0  {'max_depth': 51, 'min_samples_split': 10, 'n_...   \n",
       "149999              1.0  {'max_depth': 51, 'min_samples_split': 10, 'n_...   \n",
       "\n",
       "        n_estimators  max_depth  min_samples_split  \n",
       "0                  1          1                  1  \n",
       "1                  1          1                  1  \n",
       "2                  1          1                  1  \n",
       "3                  1          1                  1  \n",
       "4                  1          1                  1  \n",
       "...              ...        ...                ...  \n",
       "149995             1          1                  1  \n",
       "149996             1          1                  1  \n",
       "149997             1          1                  1  \n",
       "149998             1          1                  1  \n",
       "149999             1          1                  1  \n",
       "\n",
       "[150000 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fig[\"n_estimators\"] = 1\n",
    "df_fig['max_depth'] = 1\n",
    "df_fig[\"min_samples_split\"] = 1\n",
    "df_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b20011c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>params</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 1, 'n_es...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 1, 'n_es...</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 1, 'n_es...</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 1, 'n_es...</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 1, 'n_es...</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149995</th>\n",
       "      <td>1.0</td>\n",
       "      <td>{'max_depth': 51, 'min_samples_split': 10, 'n_...</td>\n",
       "      <td>2969</td>\n",
       "      <td>51</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149996</th>\n",
       "      <td>1.0</td>\n",
       "      <td>{'max_depth': 51, 'min_samples_split': 10, 'n_...</td>\n",
       "      <td>2979</td>\n",
       "      <td>51</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149997</th>\n",
       "      <td>1.0</td>\n",
       "      <td>{'max_depth': 51, 'min_samples_split': 10, 'n_...</td>\n",
       "      <td>2989</td>\n",
       "      <td>51</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149998</th>\n",
       "      <td>1.0</td>\n",
       "      <td>{'max_depth': 51, 'min_samples_split': 10, 'n_...</td>\n",
       "      <td>2999</td>\n",
       "      <td>51</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149999</th>\n",
       "      <td>1.0</td>\n",
       "      <td>{'max_depth': 51, 'min_samples_split': 10, 'n_...</td>\n",
       "      <td>3010</td>\n",
       "      <td>51</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        mean_test_score                                             params  \\\n",
       "0                   NaN  {'max_depth': 1, 'min_samples_split': 1, 'n_es...   \n",
       "1                   NaN  {'max_depth': 1, 'min_samples_split': 1, 'n_es...   \n",
       "2                   NaN  {'max_depth': 1, 'min_samples_split': 1, 'n_es...   \n",
       "3                   NaN  {'max_depth': 1, 'min_samples_split': 1, 'n_es...   \n",
       "4                   NaN  {'max_depth': 1, 'min_samples_split': 1, 'n_es...   \n",
       "...                 ...                                                ...   \n",
       "149995              1.0  {'max_depth': 51, 'min_samples_split': 10, 'n_...   \n",
       "149996              1.0  {'max_depth': 51, 'min_samples_split': 10, 'n_...   \n",
       "149997              1.0  {'max_depth': 51, 'min_samples_split': 10, 'n_...   \n",
       "149998              1.0  {'max_depth': 51, 'min_samples_split': 10, 'n_...   \n",
       "149999              1.0  {'max_depth': 51, 'min_samples_split': 10, 'n_...   \n",
       "\n",
       "        n_estimators  max_depth  min_samples_split  \n",
       "0                 10          1                  1  \n",
       "1                 20          1                  1  \n",
       "2                 30          1                  1  \n",
       "3                 40          1                  1  \n",
       "4                 50          1                  1  \n",
       "...              ...        ...                ...  \n",
       "149995          2969         51                 10  \n",
       "149996          2979         51                 10  \n",
       "149997          2989         51                 10  \n",
       "149998          2999         51                 10  \n",
       "149999          3010         51                 10  \n",
       "\n",
       "[150000 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(0,df_fig.shape[0]):\n",
    "    dict_tmp = df_fig[\"params\"].iloc[i]\n",
    "    df_fig[\"n_estimators\"].iloc[i] = dict_tmp[\"n_estimators\"]\n",
    "    df_fig[\"max_depth\"].iloc[i] = dict_tmp[\"max_depth\"]\n",
    "    df_fig[\"min_samples_split\"].iloc[i] = dict_tmp[\"min_samples_split\"]\n",
    "    \n",
    "df_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5901bd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fig.to_csv(\"tmp.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd6ad19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
